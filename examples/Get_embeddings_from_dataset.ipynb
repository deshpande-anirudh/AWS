{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJmZhc_SvNrw"
      },
      "source": [
        "# Get embeddings from dataset\n",
        "\n",
        "This notebook gives an example on how to get embeddings from a large dataset.\n",
        "\n",
        "\n",
        "## 1. Load the dataset\n",
        "\n",
        "The dataset used in this example is [fine-food reviews](https://www.kaggle.com/snap/amazon-fine-food-reviews) from Amazon. The dataset contains a total of 568,454 food reviews Amazon users left up to October 2012. We will use a subset of this dataset, consisting of 1,000 most recent reviews for illustration purposes. The reviews are in English and tend to be positive or negative. Each review has a ProductId, UserId, Score, review title (Summary) and review body (Text).\n",
        "\n",
        "We will combine the review summary and review text into a single combined text. The model will encode this combined text and it will output a single vector embedding."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap as tr\n",
        "from typing import List, Optional\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from scipy import spatial\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
        "\n",
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "client = OpenAI(max_retries=5)\n",
        "\n",
        "\n",
        "def get_embedding(text: str, model=\"text-embedding-3-small\", **kwargs) -> List[float]:\n",
        "    # replace newlines, which can negatively affect performance.\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "\n",
        "    response = client.embeddings.create(input=[text], model=model, **kwargs)\n",
        "\n",
        "    return response.data[0].embedding\n",
        "\n",
        "\n",
        "async def aget_embedding(\n",
        "    text: str, model=\"text-embedding-3-small\", **kwargs\n",
        ") -> List[float]:\n",
        "    # replace newlines, which can negatively affect performance.\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "\n",
        "    return (await client.embeddings.create(input=[text], model=model, **kwargs))[\n",
        "        \"data\"\n",
        "    ][0][\"embedding\"]\n",
        "\n",
        "\n",
        "def get_embeddings(\n",
        "    list_of_text: List[str], model=\"text-embedding-3-small\", **kwargs\n",
        ") -> List[List[float]]:\n",
        "    assert len(list_of_text) <= 2048, \"The batch size should not be larger than 2048.\"\n",
        "\n",
        "    # replace newlines, which can negatively affect performance.\n",
        "    list_of_text = [text.replace(\"\\n\", \" \") for text in list_of_text]\n",
        "\n",
        "    data = client.embeddings.create(input=list_of_text, model=model, **kwargs).data\n",
        "    return [d.embedding for d in data]\n",
        "\n",
        "\n",
        "async def aget_embeddings(\n",
        "    list_of_text: List[str], model=\"text-embedding-3-small\", **kwargs\n",
        ") -> List[List[float]]:\n",
        "    assert len(list_of_text) <= 2048, \"The batch size should not be larger than 2048.\"\n",
        "\n",
        "    # replace newlines, which can negatively affect performance.\n",
        "    list_of_text = [text.replace(\"\\n\", \" \") for text in list_of_text]\n",
        "\n",
        "    data = (\n",
        "        await client.embeddings.create(input=list_of_text, model=model, **kwargs)\n",
        "    ).data\n",
        "    return [d.embedding for d in data]\n",
        "\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "\n",
        "\n",
        "def plot_multiclass_precision_recall(\n",
        "    y_score, y_true_untransformed, class_list, classifier_name\n",
        "):\n",
        "    \"\"\"\n",
        "    Precision-Recall plotting for a multiclass problem. It plots average precision-recall, per class precision recall and reference f1 contours.\n",
        "\n",
        "    Code slightly modified, but heavily based on https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html\n",
        "    \"\"\"\n",
        "    n_classes = len(class_list)\n",
        "    y_true = pd.concat(\n",
        "        [(y_true_untransformed == class_list[i]) for i in range(n_classes)], axis=1\n",
        "    ).values\n",
        "\n",
        "    # For each class\n",
        "    precision = dict()\n",
        "    recall = dict()\n",
        "    average_precision = dict()\n",
        "    for i in range(n_classes):\n",
        "        precision[i], recall[i], _ = precision_recall_curve(y_true[:, i], y_score[:, i])\n",
        "        average_precision[i] = average_precision_score(y_true[:, i], y_score[:, i])\n",
        "\n",
        "    # A \"micro-average\": quantifying score on all classes jointly\n",
        "    precision_micro, recall_micro, _ = precision_recall_curve(\n",
        "        y_true.ravel(), y_score.ravel()\n",
        "    )\n",
        "    average_precision_micro = average_precision_score(y_true, y_score, average=\"micro\")\n",
        "    print(\n",
        "        str(classifier_name)\n",
        "        + \" - Average precision score over all classes: {0:0.2f}\".format(\n",
        "            average_precision_micro\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # setup plot details\n",
        "    plt.figure(figsize=(9, 10))\n",
        "    f_scores = np.linspace(0.2, 0.8, num=4)\n",
        "    lines = []\n",
        "    labels = []\n",
        "    for f_score in f_scores:\n",
        "        x = np.linspace(0.01, 1)\n",
        "        y = f_score * x / (2 * x - f_score)\n",
        "        (l,) = plt.plot(x[y >= 0], y[y >= 0], color=\"gray\", alpha=0.2)\n",
        "        plt.annotate(\"f1={0:0.1f}\".format(f_score), xy=(0.9, y[45] + 0.02))\n",
        "\n",
        "    lines.append(l)\n",
        "    labels.append(\"iso-f1 curves\")\n",
        "    (l,) = plt.plot(recall_micro, precision_micro, color=\"gold\", lw=2)\n",
        "    lines.append(l)\n",
        "    labels.append(\n",
        "        \"average Precision-recall (auprc = {0:0.2f})\" \"\".format(average_precision_micro)\n",
        "    )\n",
        "\n",
        "    for i in range(n_classes):\n",
        "        (l,) = plt.plot(recall[i], precision[i], lw=2)\n",
        "        lines.append(l)\n",
        "        labels.append(\n",
        "            \"Precision-recall for class `{0}` (auprc = {1:0.2f})\"\n",
        "            \"\".format(class_list[i], average_precision[i])\n",
        "        )\n",
        "\n",
        "    fig = plt.gcf()\n",
        "    fig.subplots_adjust(bottom=0.25)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel(\"Recall\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.title(f\"{classifier_name}: Precision-Recall curve for each class\")\n",
        "    plt.legend(lines, labels)\n",
        "\n",
        "\n",
        "def distances_from_embeddings(\n",
        "    query_embedding: List[float],\n",
        "    embeddings: List[List[float]],\n",
        "    distance_metric=\"cosine\",\n",
        ") -> List[List]:\n",
        "    \"\"\"Return the distances between a query embedding and a list of embeddings.\"\"\"\n",
        "    distance_metrics = {\n",
        "        \"cosine\": spatial.distance.cosine,\n",
        "        \"L1\": spatial.distance.cityblock,\n",
        "        \"L2\": spatial.distance.euclidean,\n",
        "        \"Linf\": spatial.distance.chebyshev,\n",
        "    }\n",
        "    distances = [\n",
        "        distance_metrics[distance_metric](query_embedding, embedding)\n",
        "        for embedding in embeddings\n",
        "    ]\n",
        "    return distances\n",
        "\n",
        "\n",
        "def indices_of_nearest_neighbors_from_distances(distances) -> np.ndarray:\n",
        "    \"\"\"Return a list of indices of nearest neighbors from a list of distances.\"\"\"\n",
        "    return np.argsort(distances)\n",
        "\n",
        "\n",
        "def pca_components_from_embeddings(\n",
        "    embeddings: List[List[float]], n_components=2\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Return the PCA components of a list of embeddings.\"\"\"\n",
        "    pca = PCA(n_components=n_components)\n",
        "    array_of_embeddings = np.array(embeddings)\n",
        "    return pca.fit_transform(array_of_embeddings)\n",
        "\n",
        "\n",
        "def tsne_components_from_embeddings(\n",
        "    embeddings: List[List[float]], n_components=2, **kwargs\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Returns t-SNE components of a list of embeddings.\"\"\"\n",
        "    # use better defaults if not specified\n",
        "    if \"init\" not in kwargs.keys():\n",
        "        kwargs[\"init\"] = \"pca\"\n",
        "    if \"learning_rate\" not in kwargs.keys():\n",
        "        kwargs[\"learning_rate\"] = \"auto\"\n",
        "    tsne = TSNE(n_components=n_components, **kwargs)\n",
        "    array_of_embeddings = np.array(embeddings)\n",
        "    return tsne.fit_transform(array_of_embeddings)\n",
        "\n",
        "\n",
        "def chart_from_components(\n",
        "    components: np.ndarray,\n",
        "    labels: Optional[List[str]] = None,\n",
        "    strings: Optional[List[str]] = None,\n",
        "    x_title=\"Component 0\",\n",
        "    y_title=\"Component 1\",\n",
        "    mark_size=5,\n",
        "    **kwargs,\n",
        "):\n",
        "    \"\"\"Return an interactive 2D chart of embedding components.\"\"\"\n",
        "    empty_list = [\"\" for _ in components]\n",
        "    data = pd.DataFrame(\n",
        "        {\n",
        "            x_title: components[:, 0],\n",
        "            y_title: components[:, 1],\n",
        "            \"label\": labels if labels else empty_list,\n",
        "            \"string\": [\"<br>\".join(tr.wrap(string, width=30)) for string in strings]\n",
        "            if strings\n",
        "            else empty_list,\n",
        "        }\n",
        "    )\n",
        "    chart = px.scatter(\n",
        "        data,\n",
        "        x=x_title,\n",
        "        y=y_title,\n",
        "        color=\"label\" if labels else None,\n",
        "        symbol=\"label\" if labels else None,\n",
        "        hover_data=[\"string\"] if strings else None,\n",
        "        **kwargs,\n",
        "    ).update_traces(marker=dict(size=mark_size))\n",
        "    return chart\n",
        "\n",
        "\n",
        "def chart_from_components_3D(\n",
        "    components: np.ndarray,\n",
        "    labels: Optional[List[str]] = None,\n",
        "    strings: Optional[List[str]] = None,\n",
        "    x_title: str = \"Component 0\",\n",
        "    y_title: str = \"Component 1\",\n",
        "    z_title: str = \"Compontent 2\",\n",
        "    mark_size: int = 5,\n",
        "    **kwargs,\n",
        "):\n",
        "    \"\"\"Return an interactive 3D chart of embedding components.\"\"\"\n",
        "    empty_list = [\"\" for _ in components]\n",
        "    data = pd.DataFrame(\n",
        "        {\n",
        "            x_title: components[:, 0],\n",
        "            y_title: components[:, 1],\n",
        "            z_title: components[:, 2],\n",
        "            \"label\": labels if labels else empty_list,\n",
        "            \"string\": [\"<br>\".join(tr.wrap(string, width=30)) for string in strings]\n",
        "            if strings\n",
        "            else empty_list,\n",
        "        }\n",
        "    )\n",
        "    chart = px.scatter_3d(\n",
        "        data,\n",
        "        x=x_title,\n",
        "        y=y_title,\n",
        "        z=z_title,\n",
        "        color=\"label\" if labels else None,\n",
        "        symbol=\"label\" if labels else None,\n",
        "        hover_data=[\"string\"] if strings else None,\n",
        "        **kwargs,\n",
        "    ).update_traces(marker=dict(size=mark_size))\n",
        "    return chart"
      ],
      "metadata": {
        "id": "7_JLwKN9vdsN",
        "outputId": "cf5d7e74-6b86-45de-db3a-499dbef9757b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OpenAIError",
          "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6704e0bbd08f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             raise OpenAIError(\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0;34m\"The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             )\n",
            "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3iuFLlVvNry"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tiktoken\n",
        "\n",
        "from utils.embeddings_utils import get_embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OW2WRl_pvbSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsZYbYy-vNrz"
      },
      "outputs": [],
      "source": [
        "embedding_model = \"text-embedding-3-small\"\n",
        "embedding_encoding = \"cl100k_base\"\n",
        "max_tokens = 8000  # the maximum for text-embedding-3-small is 8191"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcxnlkmxvNry"
      },
      "source": [
        "To run this notebook, you will need to install: pandas, openai, transformers, plotly, matplotlib, scikit-learn, torch (transformer dep), torchvision, and scipy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8B-TEOYvNrz",
        "outputId": "1b8d0177-6fdb-4940-9d32-9f4a611f2eed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>Score</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "      <th>combined</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1351123200</td>\n",
              "      <td>B003XPF9BO</td>\n",
              "      <td>A3R7JR3FMEBXQB</td>\n",
              "      <td>5</td>\n",
              "      <td>where does one  start...and stop... with a tre...</td>\n",
              "      <td>Wanted to save some to bring to my Chicago fam...</td>\n",
              "      <td>Title: where does one  start...and stop... wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1351123200</td>\n",
              "      <td>B003JK537S</td>\n",
              "      <td>A3JBPC3WFUT5ZP</td>\n",
              "      <td>1</td>\n",
              "      <td>Arrived in pieces</td>\n",
              "      <td>Not pleased at all. When I opened the box, mos...</td>\n",
              "      <td>Title: Arrived in pieces; Content: Not pleased...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Time   ProductId          UserId  Score  \\\n",
              "0  1351123200  B003XPF9BO  A3R7JR3FMEBXQB      5   \n",
              "1  1351123200  B003JK537S  A3JBPC3WFUT5ZP      1   \n",
              "\n",
              "                                             Summary  \\\n",
              "0  where does one  start...and stop... with a tre...   \n",
              "1                                  Arrived in pieces   \n",
              "\n",
              "                                                Text  \\\n",
              "0  Wanted to save some to bring to my Chicago fam...   \n",
              "1  Not pleased at all. When I opened the box, mos...   \n",
              "\n",
              "                                            combined  \n",
              "0  Title: where does one  start...and stop... wit...  \n",
              "1  Title: Arrived in pieces; Content: Not pleased...  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load & inspect dataset\n",
        "input_datapath = \"data/fine_food_reviews_1k.csv\"  # to save space, we provide a pre-filtered dataset\n",
        "df = pd.read_csv(input_datapath, index_col=0)\n",
        "df = df[[\"Time\", \"ProductId\", \"UserId\", \"Score\", \"Summary\", \"Text\"]]\n",
        "df = df.dropna()\n",
        "df[\"combined\"] = (\n",
        "    \"Title: \" + df.Summary.str.strip() + \"; Content: \" + df.Text.str.strip()\n",
        ")\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qm3CLpQvNrz",
        "outputId": "91a97909-573c-4f52-d60e-1b2cb68a0b08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# subsample to 1k most recent reviews and remove samples that are too long\n",
        "top_n = 1000\n",
        "df = df.sort_values(\"Time\").tail(top_n * 2)  # first cut to first 2k entries, assuming less than half will be filtered out\n",
        "df.drop(\"Time\", axis=1, inplace=True)\n",
        "\n",
        "encoding = tiktoken.get_encoding(embedding_encoding)\n",
        "\n",
        "# omit reviews that are too long to embed\n",
        "df[\"n_tokens\"] = df.combined.apply(lambda x: len(encoding.encode(x)))\n",
        "df = df[df.n_tokens <= max_tokens].tail(top_n)\n",
        "len(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja43Yim3vNrz"
      },
      "source": [
        "## 2. Get embeddings and save them for future reuse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzNJ46AuvNrz"
      },
      "outputs": [],
      "source": [
        "# Ensure you have your API key set in your environment per the README: https://github.com/openai/openai-python#usage\n",
        "\n",
        "# This may take a few minutes\n",
        "df[\"embedding\"] = df.combined.apply(lambda x: get_embedding(x, model=embedding_model))\n",
        "df.to_csv(\"data/fine_food_reviews_with_embeddings_1k.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSesH95zvNr1"
      },
      "outputs": [],
      "source": [
        "a = get_embedding(\"hi\", model=embedding_model)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "openai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "365536dcbde60510dc9073d6b991cd35db2d9bac356a11f5b64279a5e6708b97"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}